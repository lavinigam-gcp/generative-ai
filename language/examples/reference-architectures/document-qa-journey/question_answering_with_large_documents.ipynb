{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ur8xi4C7S06n"
   },
   "outputs": [],
   "source": [
    "# Copyright 2023 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JAPoU8Sm5E6e"
   },
   "source": [
    "# Question Answering with Large Documents - Foundations\n",
    "\n",
    "\n",
    "<table align=\"left\">\n",
    "\n",
    "  <td>\n",
    "    <a href=\"https://colab.research.google.com/github/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/question_answering_with_large_documents.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/colab-logo-32px.png\" alt=\"Colab logo\"> Run in Colab\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://github.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/question_answering_with_large_documents.ipynb\">\n",
    "      <img src=\"https://cloud.google.com/ml-engine/images/github-logo-32px.png\" alt=\"GitHub logo\">\n",
    "      View on GitHub\n",
    "    </a>\n",
    "  </td>\n",
    "  <td>\n",
    "    <a href=\"https://console.cloud.google.com/vertex-ai/workbench/deploy-notebook?download_url=https://raw.githubusercontent.com/GoogleCloudPlatform/generative-ai/blob/main/language/examples/reference-architectures/question_answering_with_large_documents.ipynb\">\n",
    "      <img src=\"https://lh3.googleusercontent.com/UiNooY4LUgW_oTvpsNhPpQzsstV5W8F7rYgxgGBD85cWJoLmrOzhVs_ksK_vgx40SHs7jCqkTkCk=e14-rj-sc0xffffff-h130-w32\" alt=\"Vertex AI logo\">\n",
    "      Open in Vertex AI Workbench\n",
    "    </a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tvgnzT1CKxrO"
   },
   "source": [
    "## Overview\n",
    "\n",
    "You are a Data Scientist in a company and have been tasked to build a question-answering system using Vertex PaLM API. The system should be able to take the company's documents and extract or query important information. You are simply building an out-of-box question-answering bot on enterprise data that can be in any format, such as \"PDF,\" \"DOC,\" \"TXT,\" \"DOCX,\" \"PPTX,\" \"HTML,\" etc.  \n",
    "\n",
    "The token limit is the current challenge and limitation with large language models, including [Vertex PaLM API](). As you have seen in the basic [question-answering notebook](), to get the best results from PaLM 2 Model, you must provide relevant context while asking `closed-domain` questions. Unfortunately, enterprise data do not follow such restrictions, and underlying documents could have thousands or millions of pages, which means you won't be able to pass them as context. \n",
    "\n",
    "In this `reference-architecture`, you will see two methods that can address the large context challenge, known as : \n",
    "\n",
    "* Chunk Learning - splitting documents in smaller chunks.\n",
    "* Chunk Embedding Learning - creating embeddings of smaller chunks and using vector similarity search to find relevant context. \n",
    "\n",
    "The notebook introduces you to the foundational theory of handling huge documents for building a question-answering bot using Vertex PaLM API and finding relevant context for a user query, keeping the context limitation in check. \n",
    "\n",
    "In addition, there can be open source or Google Cloud drop-in replacement of steps, which will be discussed later in the notebook. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d975e698c9a4"
   },
   "source": [
    "### Objective\n",
    "\n",
    "By the end of the notebook, you will learn how to build a question-answering system using PaLM API, which can handle large documents. \n",
    "You will also learn the conceptual implementation of two methods to help you embed large contexts from many documents. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QDU0XJ1xRDlL"
   },
   "source": [
    "## Getting Started"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2a5AEr0lkLKD"
   },
   "source": [
    "### Install Vertex AI SDK & Other dependencies "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Base system dependencies\n",
    "!sudo apt -y -qq install tesseract-ocr\n",
    "!sudo apt -y -qq install libtesseract-dev\n",
    "!sudo apt-get -y -qq install poppler-utils #required by PyPDF2 for page count and other pdf utilities\n",
    "!sudo apt-get -y -qq install python-dev libxml2-dev libxslt1-dev antiword unrtf poppler-utils pstotext tesseract-ocr flac ffmpeg lame libmad0 libsox-fmt-mp3 sox libjpeg-dev swig\n",
    "#Python dependencies\n",
    "!pip install google-cloud-aiplatform --upgrade --quiet --user\n",
    "!pip install pytesseract --quiet --user\n",
    "!pip install PyPDF2 --quiet --user\n",
    "!pip install textract --quiet --user"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Colab only**: Uncomment the following cell to restart the kernel. For Vertex AI Workbench you can restart the terminal using the button on top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_Hsqwn4hkLKE"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Automatically restart kernel after installs so that your environment can access the new packages\n",
    "# import IPython\n",
    "\n",
    "# app = IPython.Application.instance()\n",
    "# app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xe7OuYuGkLKF"
   },
   "source": [
    "### Authenticating your notebook environment\n",
    "* If you are using **Colab** to run this notebook, uncomment the cell below and continue.\n",
    "* If you are using **Vertex AI Workbench**, check out the setup instructions [here](https://github.com/GoogleCloudPlatform/generative-ai/tree/main/setup-env)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "U9Gx2SAZkLKF"
   },
   "outputs": [],
   "source": [
    "# from google.colab import auth\n",
    "# auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "960505627ddf"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "id": "PyQmSRbKA8r-"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from vertexai.preview.language_models import TextGenerationModel,TextEmbeddingModel\n",
    "from tenacity import retry, stop_after_attempt, wait_random_exponential\n",
    "from PyPDF2 import PdfReader\n",
    "import glob\n",
    "import textract\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UP76a2la7O-a"
   },
   "source": [
    "### Import models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "id": "7isig7e07O-a"
   },
   "outputs": [],
   "source": [
    "generation_model = TextGenerationModel.from_pretrained(\"text-bison@001\")\n",
    "embedding_model = TextEmbeddingModel.from_pretrained(\"textembedding-gecko@001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make PaLM API calls more resilient since you will make many calls to the API in this notebook, you should allow specific API calls to be retried before they fail. We should not \"hammer\" or \"congest\" our underlying foundation models, so it is wise to wait a bit before a retry. \n",
    "\n",
    "You can add a simple delay before every request; however, adding a fixed delay only helps if it allows the service enough time to catch up. Alternatively, a simple approach is to increase the length of the delay for each subsequent attempt. \n",
    "\n",
    "The constant used for the delay may need to be adjusted depending on the service you're calling. This is commonly refered to as [exponential backoff](https://en.wikipedia.org/wiki/Exponential_backoff)\n",
    "\n",
    "You can find more retry strategies that works best for Google Cloud APIs [here](https://cloud.google.com/storage/docs/retry-strategy) and API guide for the current method [here](https://tenacity.readthedocs.io/en/latest/api.html)\n",
    "\n",
    "You can see an example below to make a function that implements a \"retry and exponential backoff.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#To avoid hitting quota limit since you might hit the APIs multiple times in this notebook. \n",
    "# Each retry occurs at a random time in a geometrically expanding interval. \n",
    "# It allows for a custom multiplier and an ability to restrict the upper limit of the random interval to some maximum value.\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def text_generation_model_with_backoff(**kwargs):\n",
    "    return generation_model.predict(**kwargs).text\n",
    "\n",
    "\n",
    "@retry(wait=wait_random_exponential(min=1, max=20), stop=stop_after_attempt(3))\n",
    "def embedding_model_with_backoff(text=[]):\n",
    "    embeddings = embedding_model.get_embeddings(text)\n",
    "    return [each.values for each in embeddings][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fIPcn5dZ7O-b"
   },
   "source": [
    "## Question Answering with large Documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basic Method\n",
    "Before you dive deeper into correct methods for large document question-answering, explore the primary process of building the system and how it fails with larger files and context. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Basic Method](https://storage.googleapis.com/document-examples-llm/assets/basic_method_flow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://document-examples-llm/documents/20230426_alphabet_10Q.pdf...\n",
      "Copying gs://document-examples-llm/documents/20210203_alphabet_10K.pdf...\n",
      "Copying gs://document-examples-llm/documents/20220202_alphabet_10K.pdf...       \n",
      "Copying gs://document-examples-llm/documents/MLOps Whitepaper.pptx...           \n",
      "Copying gs://document-examples-llm/documents/20230203_alphabet_10K.pdf...       \n",
      "Copying gs://document-examples-llm/documents/practitioners_guide_to_mlops_whitepaper.pdf...\n",
      "Copying gs://document-examples-llm/documents/MLOps Whitepaper.json...           \n",
      "Copying gs://document-examples-llm/documents/practitioners_guide_to_mlops_whitepaper.txt...\n",
      "Copying gs://document-examples-llm/documents/mlops_whitepaper_page18.jpg...     \n",
      "Copying gs://document-examples-llm/documents/mlops_whitepaper_page22.png...     \n",
      "Copying gs://document-examples-llm/documents/practitioners_guide_to_mlops_whitepaper.docx...\n",
      "/ [11/12 files][ 17.6 MiB/ 17.6 MiB]  99% Done                                  \r"
     ]
    }
   ],
   "source": [
    "#Copying the files from the GCS bucket to local \n",
    "!gsutil -m cp -r gs://document-examples-llm/documents ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Document Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 17.9 s, sys: 5.63 s, total: 23.6 s\n",
      "Wall time: 23.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "final_data = []\n",
    "for name in glob.glob('documents/*'):\n",
    "    file_type = name.split(\".\")[-1]\n",
    "    if file_type == \"pdf\":\n",
    "        reader = PdfReader(name)\n",
    "        for i, page in enumerate(reader.pages):\n",
    "            text = page.extract_text()\n",
    "            if text:\n",
    "                data_packet = {}\n",
    "                data_packet['file_name'] = name.split(\"/\")[-1]\n",
    "                data_packet['file_type'] = \"pdf\"\n",
    "                data_packet['page_number'] = int(i+1)\n",
    "                data_packet['content'] = text\n",
    "                final_data.append(data_packet) \n",
    "    if file_type == \"txt\":\n",
    "        text_txt = textract.process(name).decode(\"utf-8\")\n",
    "        data_packet = {}\n",
    "        data_packet['file_name'] = name.split(\"/\")[-1]\n",
    "        data_packet['file_type'] = \"txt\"\n",
    "        data_packet['page_number'] = None\n",
    "        data_packet['content'] = text_txt\n",
    "        final_data.append(data_packet)\n",
    "    if file_type == \"docx\":\n",
    "        text_docx = textract.process(name).decode(\"utf-8\")\n",
    "        data_packet = {}\n",
    "        data_packet['file_name'] = name.split(\"/\")[-1]\n",
    "        data_packet['file_type'] = \"docx\"\n",
    "        data_packet['page_number'] = None\n",
    "        data_packet['content'] = text_docx\n",
    "        final_data.append(data_packet)\n",
    "    if file_type == \"json\":\n",
    "        text_json = textract.process(name).decode(\"utf-8\")\n",
    "        data_packet = {}\n",
    "        data_packet['file_name'] = name.split(\"/\")[-1]\n",
    "        data_packet['file_type'] = \"json\"\n",
    "        data_packet['page_number'] = None\n",
    "        data_packet['content'] = text_json\n",
    "        final_data.append(data_packet) \n",
    "        \n",
    "        \n",
    "    # Add readers and processors for other file types [\"doc\",\"docx\",\"pptx\",\"jpeg\" etc.] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer ☒  Accelerated filer ☐...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Alphabet Inc.\\nForm 10-K\\nFor the Fiscal Year ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NOTE ABOUT FORWARD-LOOKING STATEMENTS\\nThis An...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>5.0</td>\n",
       "      <td>•the sufficiency and timing of our proposed re...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>practitioners_guide_to_mlops_whitepaper.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>33.0</td>\n",
       "      <td>33\\nML metadata tracking is generally integrat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>368</th>\n",
       "      <td>practitioners_guide_to_mlops_whitepaper.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>34.0</td>\n",
       "      <td>34\\nFigure 14 shows the tasks that are involve...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369</th>\n",
       "      <td>practitioners_guide_to_mlops_whitepaper.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>35.0</td>\n",
       "      <td>35\\nFigure 15.  End-to-end MLOps workflow</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>practitioners_guide_to_mlops_whitepaper.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36\\nAdditional resources\\nFor more information...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>371</th>\n",
       "      <td>practitioners_guide_to_mlops_whitepaper.txt</td>\n",
       "      <td>txt</td>\n",
       "      <td>NaN</td>\n",
       "      <td>White paper\\nMay 2021\\n\\nPractitioners guide t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>372 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       file_name file_type  page_number  \\\n",
       "0                      20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "1                      20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "2                      20210203_alphabet_10K.pdf       pdf          3.0   \n",
       "3                      20210203_alphabet_10K.pdf       pdf          4.0   \n",
       "4                      20210203_alphabet_10K.pdf       pdf          5.0   \n",
       "..                                           ...       ...          ...   \n",
       "367  practitioners_guide_to_mlops_whitepaper.pdf       pdf         33.0   \n",
       "368  practitioners_guide_to_mlops_whitepaper.pdf       pdf         34.0   \n",
       "369  practitioners_guide_to_mlops_whitepaper.pdf       pdf         35.0   \n",
       "370  practitioners_guide_to_mlops_whitepaper.pdf       pdf         36.0   \n",
       "371  practitioners_guide_to_mlops_whitepaper.txt       txt          NaN   \n",
       "\n",
       "                                               content  \n",
       "0    UNITED STATES\\nSECURITIES AND EXCHANGE COMMISS...  \n",
       "1    Large accelerated filer ☒  Accelerated filer ☐...  \n",
       "2    Alphabet Inc.\\nForm 10-K\\nFor the Fiscal Year ...  \n",
       "3    NOTE ABOUT FORWARD-LOOKING STATEMENTS\\nThis An...  \n",
       "4    •the sufficiency and timing of our proposed re...  \n",
       "..                                                 ...  \n",
       "367  33\\nML metadata tracking is generally integrat...  \n",
       "368  34\\nFigure 14 shows the tasks that are involve...  \n",
       "369          35\\nFigure 15.  End-to-end MLOps workflow  \n",
       "370  36\\nAdditional resources\\nFor more information...  \n",
       "371  White paper\\nMay 2021\\n\\nPractitioners guide t...  \n",
       "\n",
       "[372 rows x 4 columns]"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#converting the data that has been read from GCS to Pandas DataFrame for easy readibility and downstream logic \n",
    "pdf_data = pd.DataFrame.from_dict(final_data)\n",
    "pdf_data = pdf_data.sort_values(by=['file_name','page_number']) #sorting the datafram by filename and page_number\n",
    "pdf_data.reset_index(inplace=True,drop=True)\n",
    "pdf_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Document store has these different file types : \n",
      " pdf     369\n",
      "json      1\n",
      "docx      1\n",
      "txt       1\n",
      "Name: file_type, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Document store has these different file types : \\n\", pdf_data['file_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Context Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The total words in the prompt:  1539605\n"
     ]
    }
   ],
   "source": [
    "# combining all the content of the PDF as single string such that it can be passed as context.\n",
    "context = '\\n'.join(str(v) for v in pdf_data['content'].values)\n",
    "print(\"The total words in the prompt: \",len(context))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "question = \"what is the address for google headquarter\"\n",
    "prompt = f\"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "              not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "          \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vertex PaLM API - Answer Extraction & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The code failed since it won't be able to run inference on such a huge context and throws this exception:  400 Request contains an invalid argument.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"PaLM Predicted:\",generation_model.predict(\n",
    "        prompt\n",
    "    ).text)\n",
    "except Exception as e: \n",
    "    print(\"The code failed since it won't be able to run inference on such a huge context and throws this exception: \",e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, you can still run the code, if you restrict the context to first 1000 words or something which is lesser than the token limit for PaLM API. But there is a good chance you will miss getting the expected answer. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1298\n",
      "PaLM Predicted: 1600 Amphitheatre Parkway  \n",
      "Mountain View , CA 94043\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the address for google headquarter\"\n",
    "prompt = f\"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "              not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "            Context: \\n {context[:1000]}?\\n\n",
    "            Question: \\n {question} \\n\n",
    "            Answer:\n",
    "          \"\"\"\n",
    "print(len(prompt))\n",
    "print(\"PaLM Predicted:\",generation_model.predict(\n",
    "    prompt\n",
    ").text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 1: Chunk Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Chunk Learning, rather than passing the whole document as context, we break the document into manageble chunks (Some times splitting by page or maybe more smaller like paragraphs) and then desing a prompt that can ask the question to each chunk. In our case, lets send each page content as a context and see how it performs. We have to make sure our prompts are designed in a way where it should output \"not available\" if the answer is not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![chunk learning](https://storage.googleapis.com/document-examples-llm/assets/chunklearning_flow.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have a lot of text in a single page, then maybe you need to divide the data much furhter. For this we can create chunks of selected size for each page. In the below code, we are divide each page into multiple chunks of 1000. You can increase or decrease it based on your data. We will maintain the page number column since it will serve as a good index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_chunks_iter(s, maxlength):\n",
    "    start = 0\n",
    "    end = 0\n",
    "    final_chunk = []\n",
    "    while start + maxlength  < len(s) and end != -1:\n",
    "        end = s.rfind(\" \", start, start + maxlength + 1)\n",
    "        final_chunk.append(s[start:end])\n",
    "        start = end +1\n",
    "    final_chunk.append(s[start:])\n",
    "    # print(len(final_chunk))\n",
    "    return final_chunk\n",
    "\n",
    "def split_text(row):\n",
    "    # print(chunk_size)\n",
    "    # print(row)\n",
    "    chunk_iter =  get_chunks_iter(row, chunk_size)\n",
    "    return chunk_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>content</th>\n",
       "      <th>chunks</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>Nasdaq Stock Market LLC Nasdaq Global Select M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>registrant was required to submit such files Y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>2020 was approximately 849 7 billion For purpo...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name file_type  page_number  \\\n",
       "0  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "1  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "2  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "3  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "4  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "\n",
       "                                             content  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  Large accelerated filer Accelerated filer Non ...   \n",
       "\n",
       "                                              chunks  \n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...  \n",
       "1  Nasdaq Stock Market LLC Nasdaq Global Select M...  \n",
       "2  registrant was required to submit such files Y...  \n",
       "3  Large accelerated filer Accelerated filer Non ...  \n",
       "4  2020 was approximately 849 7 billion For purpo...  "
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "global chunk_size\n",
    "chunk_size = 1000\n",
    "\n",
    "pdf_data_sample = pdf_data.copy()\n",
    "pdf_data_sample['content'] = pdf_data_sample['content'].apply(lambda x: re.sub('[^A-Za-z0-9]+', ' ', x))\n",
    "pdf_data_sample['chunks'] = pdf_data_sample['content'].apply(split_text)\n",
    "pdf_data_sample = pdf_data_sample.explode(\"chunks\")\n",
    "pdf_data_sample = pdf_data_sample.sort_values(by=['file_name','page_number'])\n",
    "pdf_data_sample.reset_index(inplace=True,drop=True)\n",
    "pdf_data_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_answer(df):\n",
    "    prompt = f\"\"\"Answer the question as precise as possible using the provided context. If the answer is\n",
    "                not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "              Context: \\n {df['chunks']}?\\n\n",
    "              Question: \\n {question} \\n\n",
    "              Answer:\n",
    "            \"\"\"\n",
    "\n",
    "    pred =  text_generation_model_with_backoff(\n",
    "      prompt=prompt\n",
    "    )\n",
    "    return pred\n",
    "\n",
    "def get_dates(df):\n",
    "    prompt = f\"\"\"extract dates from the given context along with significance of those dates. If the dates are not available then\n",
    "              say \"dates not available\". Do not mention any date which is not given in the context \\n\\n\n",
    "              context: \\n\n",
    "              {df['content']}\n",
    "            \"\"\"\n",
    "\n",
    "    pred =  text_generation_model_with_backoff(\n",
    "      prompt=prompt\n",
    "    )\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>content</th>\n",
       "      <th>chunks</th>\n",
       "      <th>predicted_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>The address of the principal executive offices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>Nasdaq Stock Market LLC Nasdaq Global Select M...</td>\n",
       "      <td>The address of the principal executive offices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>registrant was required to submit such files Y...</td>\n",
       "      <td>The address of the principal executive offices...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>answer not available in context</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>2020 was approximately 849 7 billion For purpo...</td>\n",
       "      <td>answer not available in context</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name file_type  page_number  \\\n",
       "0  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "1  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "2  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "3  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "4  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "\n",
       "                                             content  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  Large accelerated filer Accelerated filer Non ...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  Nasdaq Stock Market LLC Nasdaq Global Select M...   \n",
       "2  registrant was required to submit such files Y...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  2020 was approximately 849 7 billion For purpo...   \n",
       "\n",
       "                                    predicted_answer  \n",
       "0  The address of the principal executive offices...  \n",
       "1  The address of the principal executive offices...  \n",
       "2  The address of the principal executive offices...  \n",
       "3                    answer not available in context  \n",
       "4                    answer not available in context  "
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data_sample_head = pdf_data_sample.head(20)\n",
    "\n",
    "question = \"what is the address for google headquarter\"\n",
    "pdf_data_sample_head['predicted_answer'] = pdf_data_sample_head.apply(get_answer,axis=1)\n",
    "pdf_data_sample_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>content</th>\n",
       "      <th>chunks</th>\n",
       "      <th>predicted_dates</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>The fiscal year end date is December 31, 2020.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>Nasdaq Stock Market LLC Nasdaq Global Select M...</td>\n",
       "      <td>The fiscal year end date is December 31, 2020.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>registrant was required to submit such files Y...</td>\n",
       "      <td>The fiscal year end date is December 31, 2020.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>The following dates are mentioned in the conte...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>2020 was approximately 849 7 billion For purpo...</td>\n",
       "      <td>The following dates are mentioned in the conte...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name file_type  page_number  \\\n",
       "0  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "1  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "2  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "3  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "4  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "\n",
       "                                             content  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  Large accelerated filer Accelerated filer Non ...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  Nasdaq Stock Market LLC Nasdaq Global Select M...   \n",
       "2  registrant was required to submit such files Y...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  2020 was approximately 849 7 billion For purpo...   \n",
       "\n",
       "                                     predicted_dates  \n",
       "0     The fiscal year end date is December 31, 2020.  \n",
       "1     The fiscal year end date is December 31, 2020.  \n",
       "2     The fiscal year end date is December 31, 2020.  \n",
       "3  The following dates are mentioned in the conte...  \n",
       "4  The following dates are mentioned in the conte...  "
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data_sample_head = pdf_data_sample.head(20)\n",
    "pdf_data_sample_head['predicted_dates'] = pdf_data_sample_head.apply(get_dates,axis=1)\n",
    "pdf_data_sample_head.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Pros: **\n",
    "\n",
    "* Precision: The precision of the answers increases using this method.\n",
    "* Multiple context Q&A [Entity Extraction]: This is the most useful method if your answer maybe available across different levels of your document. Like, there is a specific number or entity you are looking to extract which are available on most page, then this is the most efficient and precise method. Shown as `get_dates` function and `dates` column in the final dataframe.\n",
    "\n",
    "** Cons: **\n",
    "\n",
    "\n",
    "*   Multiple API Call: Each subset/chunks will call the API. Might incure cost.\n",
    "*   Slow: If your answers are available at early chunks/subsets, even then it will search through all the chunks/subsets. Its very similar to binary search. You can make it efficient by devising cleaver strategies to make sure it stops when it finds the relevant information.\n",
    "\n",
    "* Conflicting Answers: What if the relevant answer is found at multiple chunks and subsets? How would you find the correct answer? There is good chance that you will find overlapping answers. You might have to devise some cleaver ranking algorithms to fix that.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Method 2: Map Reduce - Chunk Learning with Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the biggest con we saw with the previous method for typical Q&A is that you would have to call PaLM API on all the chunks. Its good, but not the most efficient way, as we have seen.\n",
    "\n",
    "How about exploring a way, where we can figure out only top N (1 - 5) chunks which are close to intended user query and then only call the API once by passing that as context? Sounds amazing, right?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Embedding Learning](https://storage.googleapis.com/document-examples-llm/assets/embeddinglearning.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>file_type</th>\n",
       "      <th>page_number</th>\n",
       "      <th>content</th>\n",
       "      <th>chunks</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>[-0.0018616351298987865, 0.007186433300375938,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>Nasdaq Stock Market LLC Nasdaq Global Select M...</td>\n",
       "      <td>[0.009593687951564789, 0.006503074895590544, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>1.0</td>\n",
       "      <td>UNITED STATES SECURITIES AND EXCHANGE COMMISSI...</td>\n",
       "      <td>registrant was required to submit such files Y...</td>\n",
       "      <td>[0.02656714990735054, -0.007002761587500572, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>[0.0011118471156805754, -0.0008834037580527365...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20210203_alphabet_10K.pdf</td>\n",
       "      <td>pdf</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Large accelerated filer Accelerated filer Non ...</td>\n",
       "      <td>2020 was approximately 849 7 billion For purpo...</td>\n",
       "      <td>[-0.014244736172258854, -0.005289070773869753,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   file_name file_type  page_number  \\\n",
       "0  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "1  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "2  20210203_alphabet_10K.pdf       pdf          1.0   \n",
       "3  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "4  20210203_alphabet_10K.pdf       pdf          2.0   \n",
       "\n",
       "                                             content  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "2  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  Large accelerated filer Accelerated filer Non ...   \n",
       "\n",
       "                                              chunks  \\\n",
       "0  UNITED STATES SECURITIES AND EXCHANGE COMMISSI...   \n",
       "1  Nasdaq Stock Market LLC Nasdaq Global Select M...   \n",
       "2  registrant was required to submit such files Y...   \n",
       "3  Large accelerated filer Accelerated filer Non ...   \n",
       "4  2020 was approximately 849 7 billion For purpo...   \n",
       "\n",
       "                                           embedding  \n",
       "0  [-0.0018616351298987865, 0.007186433300375938,...  \n",
       "1  [0.009593687951564789, 0.006503074895590544, -...  \n",
       "2  [0.02656714990735054, -0.007002761587500572, -...  \n",
       "3  [0.0011118471156805754, -0.0008834037580527365...  \n",
       "4  [-0.014244736172258854, -0.005289070773869753,...  "
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdf_data_sample_head = pdf_data_sample.head(50)\n",
    "pdf_data_sample_head['embedding'] = pdf_data_sample_head['chunks'].apply(lambda x: embedding_model_with_backoff([x]))\n",
    "pdf_data_sample_head[\"embedding\"] = pdf_data_sample_head.embedding.apply(np.array)\n",
    "pdf_data_sample_head.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dot_product(row):\n",
    "    return np.dot(row,query_vector)\n",
    "\n",
    "def get_context_from_question(valid_question, \n",
    "                              vector_store,\n",
    "                              sort_index_value=2):\n",
    "    global query_vector\n",
    "    query_vector = np.array(embedding_model_with_backoff([valid_question]))\n",
    "    top_matched = vector_store[\"embedding\"].apply(get_dot_product).sort_values(ascending=False)[:sort_index_value].index\n",
    "    context = \" \".join(vector_store[vector_store.index.isin(top_matched)]['chunks'].values)\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PaLM Predicted: 1600 Amphitheatre Parkway Mountain View CA 94043\n",
      "CPU times: user 9.53 ms, sys: 2.63 ms, total: 12.2 ms\n",
      "Wall time: 970 ms\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "\n",
    "valid_question = \"what is the address for google headquarter\"\n",
    "\n",
    "context = get_context_from_question(valid_question, \n",
    "                                    vector_store=pdf_data_sample_head,\n",
    "                                    sort_index_value=1 #Top N results to pick from embedding vector search\n",
    "                                   )\n",
    "\n",
    "prompt = f\"\"\" Answer the question as precise as possible using the provided context. If the answer is\n",
    "            not contained in the context, say \"answer not available in context\" \\n\\n\n",
    "            Context: \\n {context}?\\n\n",
    "            Question: \\n {valid_question} \\n\n",
    "            Answer:\n",
    "          \"\"\"\n",
    "print(\"PaLM Predicted:\",text_generation_model_with_backoff(\n",
    "    prompt=prompt\n",
    "))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "question_answering.ipynb",
   "toc_visible": true
  },
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m108",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m108"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
